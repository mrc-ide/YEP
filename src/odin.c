// Automatically generated by odin 1.4.5 - do not edit
#include <float.h>
#include <R.h>
#include <Rmath.h>
#include <Rinternals.h>
#include <stdbool.h>
#include <R_ext/Rdynload.h>
#ifndef _RING_H_
#define _RING_H_

#ifndef RING_USE_STDLIB_ALLOC
#ifndef USING_R
#define USING_R
#endif
#endif

// Allow use from C++
#ifdef __cplusplus
extern "C" {
#endif

// What to do on overflow.
//
// The OVERFLOW_ERROR action (which calls R's error function) is only
// available when using R, which is detected by the <R.h> header
// included.  If you are using RING_USE_STDLIB_ALLOC (see below) but
// want to use OVERFLOW_ERROR then you'll need to include <R.h> as
// well, and be willing to deal with an R error and the longjmp that
// it causes.
typedef enum overflow_action {
  OVERFLOW_OVERWRITE,
  OVERFLOW_GROW
#ifdef USING_R
  , OVERFLOW_ERROR
#endif
} overflow_action;

// The underlying data structure.  None of the fields here should be
// directly accessed in normal use; use the accessor functions
// instead.
//
// The ring buffer is a FIFO (first-in-first-out) queue.  It is
// implemented as a single block of memory (data) and a pair of
// pointers:
//
//   head: the starting location where data should be written when
//         copying data *into* the buffer.
//
//   tail: the starting location where data should be read when
//         copying data *from* the buffer.
//
// The buffer has a concept of a stride; the number of bytes per
// buffer entry.  This is fixed across the entire ring.  As such, some
// functions that return size_t have a booleanargument "bytes" that
// switches between measuring in bytes and measuring in logical
// elements.  In the case where stride=1, these are identical.
//
// In general, the ring buffer is totally happy to overflow; if you
// write too much into the ring buffer it will destructively erase
// data (i.e., your tail will move).  The ring buffer will never
// underflow, but functions may return `NULL` on underflow - read the
// documentation below carefully.
typedef unsigned char data_t;
typedef struct ring_buffer {
  size_t size;
  size_t stride;
  size_t bytes_data;
  overflow_action on_overflow;

  data_t *data;
  data_t *head;
  data_t *tail;
} ring_buffer;

//// Creation, deletion, etc: ////

// Create a ring buffer.  After creating, be sure to free the memory
// with `ring_buffer_destroy`.
//
//   size: (maximum) number of elements that the ring buffer may contain
//
//   stride: number of *bytes* per ring buffer element
//
// See the note above the struct for details on size/stride.
//
// If the buffer cannot be allocated (e.g., too big a buffer is
// requested) then an R error will be thrown as this uses `Calloc`.
//
// This may not always be desirable (e.g., if using from within C++,
// or in a project that does not actually use R).  To use plain C
// stdlib calloc/free, in the ring.c use:
//
//     #define RING_USE_STDLIB_ALLOC 1
//     #include <ring/ring.c>
//
// which will not depend on *any* R code and use stdlib calloc/free
// (except for the issue with USING_R/OVERFLOW_ERROR above).  With
// RING_USE_STDLIB_ALLOC defined, if an allocation fails, then
// ring_buffer_create (and ring_buffer_duplicate below) will return
// NULL.  So if using this approach be sure to check the return value!
//
// The main wrinkle to using RING_USE_STDLIB_ALLOC 1 is that the
// `overflow_action` `OVERFLOW_ERROR` will not work.  At present this
// will fail to compile, but in future I may add an error handler.
ring_buffer * ring_buffer_create(size_t size, size_t stride,
                                 overflow_action on_overflow);

// Destroy a ring buffer.  Frees the memory
//
//   buffer: the ring buffer to copy; after calling this function all
//           memory associated with the buffer is freed.
void ring_buffer_destroy(ring_buffer *buffer);

// Duplicate (copy) a ring buffer.  Copies both the underlying data and
// the position of the head and tail.  A new buffer will be allocated
// and must be freed when finished with, using `ring_buffer_destroy`
//
//   buffer: a ring buffer to copy from; will not be modified
ring_buffer * ring_buffer_duplicate(const ring_buffer *buffer);

// Increase the size of the ring buffer so that it can hold additional
// elements.  This does not alter existing elements but increases the
// capacity (similar to he `reserve` method in the C++ standard
// library).
//
//   buffer: a ring buffer to increase the size of
//
//   n: the number of elements to increase the buffer by
//
//   exact: boolean, indicating if the buffer should be increased by
//          exactly `n` elements (if true) or by at least `n` elements
//          (if false).  If using the inexact method, the buffer is
//          increased in size using geometric growth using the golden
//          ratio.
//
// After using this function, all references to the head or tail are
// broken and the memory may have been freed and the contents moved
// elsewhere.
//
// If RING_USE_STDLIB_ALLOC is defined, and if an allocation fails,
// then this may leave things in an undesirable state (this is
// particularly a problem when using on_overflow = OVERFLOW_GROW).
// Currently, if R is used an R error will be thrown (possibly not a
// good idea if running under Rcpp) and if running as a standalone
// application then the data will be set to NULL, probably causing a
// crash pretty quickly (improvements welcome).
void ring_buffer_grow(ring_buffer *buffer, size_t n, bool exact);

// Reset the state of the buffer.  This "zeros" the head and tail
// pointer (and may or may not actually reset the data) so that the
// buffer can be used as if fresh.
//
//   buffer: a ring buffer to reset
//
//   clear: boolean, indicating if memory should also be zeroed
void ring_buffer_reset(ring_buffer *buffer, bool clear);

//// Basic querying: ////

// Return the maximum size of the ring buffer
//
//   buffer: the ring buffer to test (will not be modified)
//
//   bytes: indicates if size should be in bytes (if true) or elements
//          (if false)
size_t ring_buffer_size(const ring_buffer *buffer, bool bytes);

// Report the free and used space in the ring buffer
//
//   buffer: the ring buffer to test (will not be modified)
//
//   bytes: indicates if used/free space should be in bytes (if true)
//          or elements (if false)
size_t ring_buffer_free(const ring_buffer *buffer, bool bytes);
size_t ring_buffer_used(const ring_buffer *buffer, bool bytes);

// Report the number of bytes of data that have been allocated.  Note
// that this is likely `stride` more bytes than was requested as this
// avoids a lot of awkward bookkeeping later, allowing the "full"
// state to be distinguished from the "empty" state.
size_t ring_buffer_bytes_data(const ring_buffer *buffer);

// Report if the ring buffer is full or empty
bool ring_buffer_is_full(const ring_buffer *buffer);
bool ring_buffer_is_empty(const ring_buffer *buffer);

//// Additional querying: ////

// Return the position of the head and tail pointers relative to the
// data pointer (this is an offset, so 0 means the pointer is at the
// start of the data array).
//
//   bytes: indicates if offset should be bytes (if true) or elements (if false)
size_t ring_buffer_head_pos(const ring_buffer *buffer, bool bytes);
size_t ring_buffer_tail_pos(const ring_buffer *buffer, bool bytes);

// Return pointers to the the data, head and tail members of the ring
// buffer.  These are preferred over directly accessing the "data",
// "head" and "tail" elements of the ring buffer structure itself
// because with these the compiler will enforce read-only access for
// you.
//
// WARNING: the head buffer is *not* the most recently added element,
// but instead the bit of memory that will be written to next; it's
// generally not terribly useful and a better way of getting the last
// written element is to use:
//
//   ring_buffer_head_offset(buffer, 0);
//
// which will look after wrapping the ring buffer appropriately.
const void * ring_buffer_data(const ring_buffer *buffer);
const void * ring_buffer_head(const ring_buffer *buffer);
const void * ring_buffer_tail(const ring_buffer *buffer);

//// Setting repeated values: ////

// Set all bytes of a length of the buffer to 'c'.  Here, 'len' is the
// number of *entries*, so stride * len bytes will be set.  This will
// mostly be uesful with c=0.
//
//   buffer: the ring buffer to set data into
//
//   c: value (0-255) to set all bytes to
//
//   n: number of elements to set
//
// This starts adding data at `head`.  If the buffer will overflow, at
// most `bytes_data` bytes will be written (i.e., each element will be
// written to once).
//
// Returns the number of bytes actually written to the buffer (so if
// the buffer overflows this may be less than `len`).
size_t ring_buffer_set(ring_buffer *buffer, data_t c, size_t n);

// Set a number of the elements of the buffer to a particular byte
// pattern.  In contrast with `ring_buffer_set`, this does not set
// individual bytes, but instead complete elements.
//
//    buffer: the ring buffer to set data into
//
//    x: pointer to a set of data to copy into the ring buffer.  This
//            must be (at least) stride bytes long.
//
//    n: number of elements to set
//
// This starts adding data at `head`.  If the buffer will overflow, at
// most `bytes_data` bytes will be written (i.e., each element will be
// written to once).
size_t ring_buffer_set_stride(ring_buffer *buffer, const void *x, size_t n);

//// Read and write ////

// Copy `n` entries, each of `stride` bytes from a contiguous memory
// area src into the ring `buffer`. Returns the ring buffer's new head
// pointer.
//
// It is possible to overflow the buffer with this function
//
//   buffer: the ring buffer to copy data into
//
//   src: the source memory to copy from (make sure this is big enough
//           or you will get crashes and other terrible things).
//
//   n: the number of entries to copy from `src` into `buffer` (each
//           of which is `stride` bytes long).
const void * ring_buffer_push(ring_buffer *buffer, const void *src, size_t n);

// Destructively copy `n` entries (each of which is `stride` bytes)
// from a ring buffer `buffer` into contiguous memory region `dest`.
// This updates the `tail` pointers in the ring buffer and returns the
// new tail pointer.
//
// The `n` entries will no longer be available in the ring buffer.
// To do a nondestructive read, use `ring_buffer_read()`.
//
//   buffer: the ring buffer to copy data from
//
//   dest: the destination memory to copy into (make sure this is big enough
//           or you will get crashes and other terrible things).
//
//   n: the number of entries to copy from `src` into `buffer` (each
//           of which is `stride` bytes long).
//
// This function will not allow the ring buffer to underflow.  If
// `n` is greater than the number of available entries, then
// nothing is copied (and the ring buffer remains unmodified) and NULL
// is returned.
const void * ring_buffer_take(ring_buffer *buffer, void *dest, size_t n);

// Nondestructively read from a ring buffer.  This function is
// essentially identical to `ring_buffer_take` but does not alter the
// tail pointer.
const void * ring_buffer_read(const ring_buffer *buffer, void *dest, size_t n);

// ring_buffer_take_head and ring_buffer_read_head are like
// ring_buffer_take and ring_buffer_read (respectively) but operate on
// the *head* of the ring (i.e., removing the most recently added
// elements rather than the oldest elements).
//
// Neither will underflow, returning NULL if there are not enough
// elements, and without copying anything.
const void * ring_buffer_take_head(ring_buffer *buffer, void *dest, size_t n);
const void * ring_buffer_read_head(const ring_buffer *buffer, void *dest,
                                   size_t n);

// Copy `n` entries (each of `stride` bytes) from one ring buffer
// `src` into another `dest`.  The copy starts at the tail of this
// ring buffer, pushing onto the head of the destination buffer.
//
//   src: A ring buffer to copy data from

//   dest: A ring buffer to copy data into
//
//   n: the number of entries to copy (each of which is `stride` bytes)
//
// This is destructive to both buffers as pointers will be updated in
// both.
//
// This function returns the new head pointer of the destination buffer.
//
// It is not possible to underflow `src`; if too few entries are
// available, then nothing is copied, `src` and `dest` are not
// modified, and the function returns NULL
//
// It is possible to overflow `dest` and the tail pointer will be
// updated appropriately if so.
//
// Warning: the two buffers must have the same stride.  If the buffers
// do not have the same stride, the function will return NULL (this
// means if the function returns NULL it could either be an underflow
// or an incompatible buffer).
const void * ring_buffer_copy(ring_buffer *src, ring_buffer *dest, size_t n);

// Mirror the contents of ring buffer `src` into ring buffer `dest`.
// This differs from `ring_buffer_copy` in that the `src` buffer is
// not modified and that the *entire* state of the ring buffer is
// duplicated.
//
// The function requires (and checks) that `src` and `dest` agree on
// size and stride (and therefore total bytes).  It returns `true` if
// the mirror was done, and `false` if the buffers are incompatible.
//
// This function will destroy all data in `dest`, but not allocate any
// memory.
//
// Warning: the two buffers must have the same stride *and* the same
// size.  If they do not, the function will return NULL (this means if
// the function returns NULL it could either be an underflow or an
// incompatible buffer).
bool ring_buffer_mirror(const ring_buffer *src, ring_buffer *dest);

// Returns a pointer to the tail (reading end) of the buffer, offset
// by `offset` entries.  When used as `ring_buffer_tail_offset(x, 0)`
// this is equivalent to `ring_buffer_tail(x)` except that it will do
// underflow checking.
//
//   buffer: the ring buffer to use
//
//   offset: the number of entries (each of which are `stride` bytes)
//           to offset by
//
// It is not possible to underflow the buffer here; if `offset` is so
// large that it would underflow, then NULL will be returned.
const void * ring_buffer_tail_offset(const ring_buffer *buffer, size_t offset);

// As for `ring_buffer_tail_offset`, but offsetting the *head*
// pointer.  This offsets in the opposite direction (moving from the
// most recently added element towards the oldest element).
const void * ring_buffer_head_offset(const ring_buffer *buffer, size_t offset);

//// For advanced use: ////

// Advance the ring buffer by one entry and return a pointer to the
// memory *without writing anything to it*.  In this case, the calling
// function is responsible for setting the memory to something
// sensible.  This is currently used in the dde package where we want
// to write directly to the head.
//
// This is (roughly) equivalent to:
//
//    ring_buffer_set(buffer, 0, 1);
//    return buffer->head;
//
// but does not actually copy any data.
//
// Note that the pointer returned is *not* const; this is always used
// in a case where the aim is to write to the head directly!
void * ring_buffer_head_advance(ring_buffer *buffer);

//// Search: ////

// There are two functions for searching for data within a ring buffer
// that consists of *sorted* entries.  This might be the case if
// entries are added sequentially with (say) a timestamp.
//
// To locate an entry, a predicate function (pointer) must be
// provided.  This must be a function taking two void pointers as
// arguments; the first will be the pointer to an entry in the ring
// buffer, the second will be any data that *you* provide (may be
// NULL).  This function must return "true" if the value is *less
// than* the target value (i.e. true if we should search *earlier* in
// the buffer).  The "x" argument must be treated as read-only.
//
// For example, a predictate function that would find an entry where
// the first 8 bytes of a ring buffer entry represent doubles could be
// written as:
//
//     bool test_find_double(const void *x, void *data) {
//       double x_value = *((double*) x);
//       double data_value = *((double*) data);
//       return x_value <= data_value;
//     }
//
// Where the "data" argument will be passed through as the number to
// search for.
//
// These functions return NULL if no entry is found, otherwise they
// return the pointer to the largest entry in the buffer that the
// predicate returns false.
//
// The _linear search does a naive linear search from the tail of the
// buffer (i.e., the last entry that was added) towards the beginning.
//
// The _bisect search tries to be more clever and does a bisect
// search.  It requires an initial guess "i" to the location of the
// data.  You can provide '0' as 'i' to start at the tail.
//
// The "data" argument to both functions will be passed through to the
// predicate function.
typedef bool ring_predicate(const void *x, void *data);
const void * ring_buffer_search_linear(const ring_buffer *buffer,
                                       ring_predicate pred, void *data);
const void * ring_buffer_search_bisect(const ring_buffer *buffer, size_t i,
                                       ring_predicate pred, void *data);

#ifdef __cplusplus
}
#endif
#endif
typedef struct SEIRV_Model_internal {
  double beta;
  double *Cas0;
  ring_buffer *delay_ring_I_lag;
  ring_buffer *delay_ring_I_new;
  ring_buffer *delay_ring_R_new;
  int dim_C;
  int dim_Cas0;
  int dim_dP1;
  int dim_dP1_all;
  int dim_dP1_all_1;
  int dim_dP1_all_2;
  int dim_dP2;
  int dim_dP2_all;
  int dim_dP2_all_1;
  int dim_dP2_all_2;
  int dim_E;
  int dim_E_new;
  int dim_Exp0;
  int dim_I;
  int dim_I_lag;
  int dim_I_new;
  int dim_Inf0;
  int dim_inv_P;
  int dim_inv_P_nV;
  int dim_P;
  int dim_P_nV;
  int dim_R;
  int dim_R_new;
  int dim_Rec0;
  int dim_S;
  int dim_Sus0;
  int dim_V;
  int dim_Vac0;
  int dim_vacc_rate;
  int dim_vacc_rate_annual;
  int dim_vacc_rate_annual_1;
  int dim_vacc_rate_annual_2;
  double *dP1;
  double *dP1_all;
  double *dP2;
  double *dP2_all;
  double dt;
  double *E_new;
  double *Exp0;
  double FOI_max;
  double FOI_spillover;
  double *I_lag;
  double *I_new;
  double *Inf0;
  double *initial_C;
  double initial_day;
  double *initial_E;
  double initial_FOI_total;
  double *initial_I;
  double *initial_R;
  double *initial_S;
  int initial_step;
  double *initial_V;
  double initial_year;
  double *inv_P;
  double *inv_P_nV;
  int N_age;
  int n_years;
  int offset_variable_C;
  int offset_variable_E;
  int offset_variable_I;
  int offset_variable_R;
  int offset_variable_V;
  double *P;
  double *P_nV;
  double Pmin;
  double *R_new;
  double R0;
  double *Rec0;
  double *Sus0;
  double t_incubation;
  double t_infectious;
  double t_latent;
  double *Vac0;
  double *vacc_rate;
  double *vacc_rate_annual;
  double vaccine_efficacy;
  double year0;
  bool SEIRV_Model_use_dde;
} SEIRV_Model_internal;
SEIRV_Model_internal* SEIRV_Model_get_internal(SEXP internal_p, int closed_error);
static void SEIRV_Model_finalise(SEXP internal_p);
SEXP SEIRV_Model_create(SEXP user);
void SEIRV_Model_initmod_desolve(void(* odeparms) (int *, double *));
SEXP SEIRV_Model_contents(SEXP internal_p);
SEXP SEIRV_Model_set_user(SEXP internal_p, SEXP user);
SEXP SEIRV_Model_set_initial(SEXP internal_p, SEXP step_ptr, SEXP state_ptr);
SEXP SEIRV_Model_metadata(SEXP internal_p);
SEXP SEIRV_Model_initial_conditions(SEXP internal_p, SEXP step_ptr);
void SEIRV_Model_rhs(SEIRV_Model_internal* internal, size_t step, double * state, double * state_next, double * output);
void SEIRV_Model_rhs_dde(size_t n_eq, size_t step, double * state, double * state_next, size_t n_out, double * output, void * internal);
SEXP SEIRV_Model_rhs_r(SEXP internal_p, SEXP step, SEXP state);
double user_get_scalar_double(SEXP user, const char *name,
                              double default_value, double min, double max);
int user_get_scalar_int(SEXP user, const char *name,
                        int default_value, double min, double max);
void user_check_values_double(double * value, size_t len,
                                  double min, double max, const char *name);
void user_check_values_int(int * value, size_t len,
                               double min, double max, const char *name);
void user_check_values(SEXP value, double min, double max,
                           const char *name);
SEXP user_list_element(SEXP list, const char *name);
void odin_set_dim(SEXP target, int rank, ...);
void* user_get_array_dim(SEXP user, bool is_integer, void * previous,
                         const char *name, int rank,
                         double min, double max, int *dest_dim);
void* user_get_array(SEXP user, bool is_integer, void * previous,
                     const char *name, double min, double max,
                     int rank, ...);
SEXP user_get_array_check(SEXP el, bool is_integer, const char *name,
                          double min, double max);
SEXP user_get_array_check_rank(SEXP user, const char *name, int rank,
                               bool required);
double odin_sum1(double *x, size_t from, size_t to);
int odin_isum1(int *x, size_t from, size_t to);
int scalar_int(SEXP x, const char * name);
SEIRV_Model_internal* SEIRV_Model_get_internal(SEXP internal_p, int closed_error) {
  SEIRV_Model_internal *internal = NULL;
  if (TYPEOF(internal_p) != EXTPTRSXP) {
    Rf_error("Expected an external pointer");
  }
  internal = (SEIRV_Model_internal*) R_ExternalPtrAddr(internal_p);
  if (!internal && closed_error) {
    Rf_error("Pointer has been invalidated");
  }
  return internal;
}
void SEIRV_Model_finalise(SEXP internal_p) {
  SEIRV_Model_internal *internal = SEIRV_Model_get_internal(internal_p, 0);
  if (internal_p) {
    ring_buffer_destroy(internal->delay_ring_I_lag);
    ring_buffer_destroy(internal->delay_ring_I_new);
    ring_buffer_destroy(internal->delay_ring_R_new);
    internal->delay_ring_I_lag = NULL;
    internal->delay_ring_I_new = NULL;
    internal->delay_ring_R_new = NULL;
    R_Free(internal->Cas0);
    R_Free(internal->dP1);
    R_Free(internal->dP1_all);
    R_Free(internal->dP2);
    R_Free(internal->dP2_all);
    R_Free(internal->E_new);
    R_Free(internal->Exp0);
    R_Free(internal->I_lag);
    R_Free(internal->I_new);
    R_Free(internal->Inf0);
    R_Free(internal->initial_C);
    R_Free(internal->initial_E);
    R_Free(internal->initial_I);
    R_Free(internal->initial_R);
    R_Free(internal->initial_S);
    R_Free(internal->initial_V);
    R_Free(internal->inv_P);
    R_Free(internal->inv_P_nV);
    R_Free(internal->P);
    R_Free(internal->P_nV);
    R_Free(internal->R_new);
    R_Free(internal->Rec0);
    R_Free(internal->Sus0);
    R_Free(internal->Vac0);
    R_Free(internal->vacc_rate);
    R_Free(internal->vacc_rate_annual);
    R_Free(internal);
    R_ClearExternalPtr(internal_p);
  }
}
SEXP SEIRV_Model_create(SEXP user) {
  SEIRV_Model_internal *internal = (SEIRV_Model_internal*) R_Calloc(1, SEIRV_Model_internal);
  internal->Cas0 = NULL;
  internal->delay_ring_I_lag = NULL;
  internal->delay_ring_I_new = NULL;
  internal->delay_ring_R_new = NULL;
  internal->dP1 = NULL;
  internal->dP1_all = NULL;
  internal->dP2 = NULL;
  internal->dP2_all = NULL;
  internal->E_new = NULL;
  internal->Exp0 = NULL;
  internal->I_lag = NULL;
  internal->I_new = NULL;
  internal->Inf0 = NULL;
  internal->initial_C = NULL;
  internal->initial_E = NULL;
  internal->initial_I = NULL;
  internal->initial_R = NULL;
  internal->initial_S = NULL;
  internal->initial_V = NULL;
  internal->inv_P = NULL;
  internal->inv_P_nV = NULL;
  internal->P = NULL;
  internal->P_nV = NULL;
  internal->R_new = NULL;
  internal->Rec0 = NULL;
  internal->Sus0 = NULL;
  internal->Vac0 = NULL;
  internal->vacc_rate = NULL;
  internal->vacc_rate_annual = NULL;
  internal->FOI_max = 1;
  internal->initial_day = 0;
  internal->Pmin = 0;
  internal->t_incubation = 5;
  internal->t_infectious = 5;
  internal->t_latent = 5;
  internal->Cas0 = NULL;
  internal->dP1_all = NULL;
  internal->dP2_all = NULL;
  internal->dt = NA_REAL;
  internal->Exp0 = NULL;
  internal->FOI_spillover = NA_REAL;
  internal->Inf0 = NULL;
  internal->N_age = NA_INTEGER;
  internal->n_years = NA_INTEGER;
  internal->R0 = NA_REAL;
  internal->Rec0 = NULL;
  internal->Sus0 = NULL;
  internal->Vac0 = NULL;
  internal->vacc_rate_annual = NULL;
  internal->vaccine_efficacy = NA_REAL;
  internal->year0 = NA_REAL;
  SEXP ptr = PROTECT(R_MakeExternalPtr(internal, R_NilValue, R_NilValue));
  R_RegisterCFinalizer(ptr, SEIRV_Model_finalise);
  UNPROTECT(1);
  return ptr;
}
static SEIRV_Model_internal *SEIRV_Model_internal_ds;
void SEIRV_Model_initmod_desolve(void(* odeparms) (int *, double *)) {
  static DL_FUNC get_desolve_gparms = NULL;
  if (get_desolve_gparms == NULL) {
    get_desolve_gparms =
      R_GetCCallable("deSolve", "get_deSolve_gparms");
  }
  SEIRV_Model_internal_ds = SEIRV_Model_get_internal(get_desolve_gparms(), 1);
}
SEXP SEIRV_Model_contents(SEXP internal_p) {
  SEIRV_Model_internal *internal = SEIRV_Model_get_internal(internal_p, 1);
  SEXP contents = PROTECT(allocVector(VECSXP, 84));
  SET_VECTOR_ELT(contents, 0, ScalarReal(internal->beta));
  SEXP Cas0 = PROTECT(allocVector(REALSXP, internal->dim_Cas0));
  memcpy(REAL(Cas0), internal->Cas0, internal->dim_Cas0 * sizeof(double));
  SET_VECTOR_ELT(contents, 1, Cas0);
  SET_VECTOR_ELT(contents, 5, ScalarInteger(internal->dim_C));
  SET_VECTOR_ELT(contents, 6, ScalarInteger(internal->dim_Cas0));
  SET_VECTOR_ELT(contents, 7, ScalarInteger(internal->dim_dP1));
  SET_VECTOR_ELT(contents, 8, ScalarInteger(internal->dim_dP1_all));
  SET_VECTOR_ELT(contents, 9, ScalarInteger(internal->dim_dP1_all_1));
  SET_VECTOR_ELT(contents, 10, ScalarInteger(internal->dim_dP1_all_2));
  SET_VECTOR_ELT(contents, 11, ScalarInteger(internal->dim_dP2));
  SET_VECTOR_ELT(contents, 12, ScalarInteger(internal->dim_dP2_all));
  SET_VECTOR_ELT(contents, 13, ScalarInteger(internal->dim_dP2_all_1));
  SET_VECTOR_ELT(contents, 14, ScalarInteger(internal->dim_dP2_all_2));
  SET_VECTOR_ELT(contents, 15, ScalarInteger(internal->dim_E));
  SET_VECTOR_ELT(contents, 16, ScalarInteger(internal->dim_E_new));
  SET_VECTOR_ELT(contents, 17, ScalarInteger(internal->dim_Exp0));
  SET_VECTOR_ELT(contents, 18, ScalarInteger(internal->dim_I));
  SET_VECTOR_ELT(contents, 19, ScalarInteger(internal->dim_I_lag));
  SET_VECTOR_ELT(contents, 20, ScalarInteger(internal->dim_I_new));
  SET_VECTOR_ELT(contents, 21, ScalarInteger(internal->dim_Inf0));
  SET_VECTOR_ELT(contents, 22, ScalarInteger(internal->dim_inv_P));
  SET_VECTOR_ELT(contents, 23, ScalarInteger(internal->dim_inv_P_nV));
  SET_VECTOR_ELT(contents, 24, ScalarInteger(internal->dim_P));
  SET_VECTOR_ELT(contents, 25, ScalarInteger(internal->dim_P_nV));
  SET_VECTOR_ELT(contents, 26, ScalarInteger(internal->dim_R));
  SET_VECTOR_ELT(contents, 27, ScalarInteger(internal->dim_R_new));
  SET_VECTOR_ELT(contents, 28, ScalarInteger(internal->dim_Rec0));
  SET_VECTOR_ELT(contents, 29, ScalarInteger(internal->dim_S));
  SET_VECTOR_ELT(contents, 30, ScalarInteger(internal->dim_Sus0));
  SET_VECTOR_ELT(contents, 31, ScalarInteger(internal->dim_V));
  SET_VECTOR_ELT(contents, 32, ScalarInteger(internal->dim_Vac0));
  SET_VECTOR_ELT(contents, 33, ScalarInteger(internal->dim_vacc_rate));
  SET_VECTOR_ELT(contents, 34, ScalarInteger(internal->dim_vacc_rate_annual));
  SET_VECTOR_ELT(contents, 35, ScalarInteger(internal->dim_vacc_rate_annual_1));
  SET_VECTOR_ELT(contents, 36, ScalarInteger(internal->dim_vacc_rate_annual_2));
  SEXP dP1 = PROTECT(allocVector(REALSXP, internal->dim_dP1));
  memcpy(REAL(dP1), internal->dP1, internal->dim_dP1 * sizeof(double));
  SET_VECTOR_ELT(contents, 37, dP1);
  SEXP dP1_all = PROTECT(allocVector(REALSXP, internal->dim_dP1_all));
  memcpy(REAL(dP1_all), internal->dP1_all, internal->dim_dP1_all * sizeof(double));
  odin_set_dim(dP1_all, 2, internal->dim_dP1_all_1, internal->dim_dP1_all_2);
  SET_VECTOR_ELT(contents, 38, dP1_all);
  SEXP dP2 = PROTECT(allocVector(REALSXP, internal->dim_dP2));
  memcpy(REAL(dP2), internal->dP2, internal->dim_dP2 * sizeof(double));
  SET_VECTOR_ELT(contents, 39, dP2);
  SEXP dP2_all = PROTECT(allocVector(REALSXP, internal->dim_dP2_all));
  memcpy(REAL(dP2_all), internal->dP2_all, internal->dim_dP2_all * sizeof(double));
  odin_set_dim(dP2_all, 2, internal->dim_dP2_all_1, internal->dim_dP2_all_2);
  SET_VECTOR_ELT(contents, 40, dP2_all);
  SET_VECTOR_ELT(contents, 41, ScalarReal(internal->dt));
  SEXP E_new = PROTECT(allocVector(REALSXP, internal->dim_E_new));
  memcpy(REAL(E_new), internal->E_new, internal->dim_E_new * sizeof(double));
  SET_VECTOR_ELT(contents, 42, E_new);
  SEXP Exp0 = PROTECT(allocVector(REALSXP, internal->dim_Exp0));
  memcpy(REAL(Exp0), internal->Exp0, internal->dim_Exp0 * sizeof(double));
  SET_VECTOR_ELT(contents, 43, Exp0);
  SET_VECTOR_ELT(contents, 44, ScalarReal(internal->FOI_max));
  SET_VECTOR_ELT(contents, 45, ScalarReal(internal->FOI_spillover));
  SEXP I_lag = PROTECT(allocVector(REALSXP, internal->dim_I_lag));
  memcpy(REAL(I_lag), internal->I_lag, internal->dim_I_lag * sizeof(double));
  SET_VECTOR_ELT(contents, 46, I_lag);
  SEXP I_new = PROTECT(allocVector(REALSXP, internal->dim_I_new));
  memcpy(REAL(I_new), internal->I_new, internal->dim_I_new * sizeof(double));
  SET_VECTOR_ELT(contents, 47, I_new);
  SEXP Inf0 = PROTECT(allocVector(REALSXP, internal->dim_Inf0));
  memcpy(REAL(Inf0), internal->Inf0, internal->dim_Inf0 * sizeof(double));
  SET_VECTOR_ELT(contents, 48, Inf0);
  SEXP initial_C = PROTECT(allocVector(REALSXP, internal->dim_C));
  memcpy(REAL(initial_C), internal->initial_C, internal->dim_C * sizeof(double));
  SET_VECTOR_ELT(contents, 49, initial_C);
  SET_VECTOR_ELT(contents, 50, ScalarReal(internal->initial_day));
  SEXP initial_E = PROTECT(allocVector(REALSXP, internal->dim_E));
  memcpy(REAL(initial_E), internal->initial_E, internal->dim_E * sizeof(double));
  SET_VECTOR_ELT(contents, 51, initial_E);
  SET_VECTOR_ELT(contents, 52, ScalarReal(internal->initial_FOI_total));
  SEXP initial_I = PROTECT(allocVector(REALSXP, internal->dim_I));
  memcpy(REAL(initial_I), internal->initial_I, internal->dim_I * sizeof(double));
  SET_VECTOR_ELT(contents, 53, initial_I);
  SEXP initial_R = PROTECT(allocVector(REALSXP, internal->dim_R));
  memcpy(REAL(initial_R), internal->initial_R, internal->dim_R * sizeof(double));
  SET_VECTOR_ELT(contents, 54, initial_R);
  SEXP initial_S = PROTECT(allocVector(REALSXP, internal->dim_S));
  memcpy(REAL(initial_S), internal->initial_S, internal->dim_S * sizeof(double));
  SET_VECTOR_ELT(contents, 55, initial_S);
  SET_VECTOR_ELT(contents, 56, ScalarInteger(internal->initial_step));
  SEXP initial_V = PROTECT(allocVector(REALSXP, internal->dim_V));
  memcpy(REAL(initial_V), internal->initial_V, internal->dim_V * sizeof(double));
  SET_VECTOR_ELT(contents, 57, initial_V);
  SET_VECTOR_ELT(contents, 58, ScalarReal(internal->initial_year));
  SEXP inv_P = PROTECT(allocVector(REALSXP, internal->dim_inv_P));
  memcpy(REAL(inv_P), internal->inv_P, internal->dim_inv_P * sizeof(double));
  SET_VECTOR_ELT(contents, 59, inv_P);
  SEXP inv_P_nV = PROTECT(allocVector(REALSXP, internal->dim_inv_P_nV));
  memcpy(REAL(inv_P_nV), internal->inv_P_nV, internal->dim_inv_P_nV * sizeof(double));
  SET_VECTOR_ELT(contents, 60, inv_P_nV);
  SET_VECTOR_ELT(contents, 61, ScalarInteger(internal->N_age));
  SET_VECTOR_ELT(contents, 62, ScalarInteger(internal->n_years));
  SET_VECTOR_ELT(contents, 63, ScalarInteger(internal->offset_variable_C));
  SET_VECTOR_ELT(contents, 64, ScalarInteger(internal->offset_variable_E));
  SET_VECTOR_ELT(contents, 65, ScalarInteger(internal->offset_variable_I));
  SET_VECTOR_ELT(contents, 66, ScalarInteger(internal->offset_variable_R));
  SET_VECTOR_ELT(contents, 67, ScalarInteger(internal->offset_variable_V));
  SEXP P = PROTECT(allocVector(REALSXP, internal->dim_P));
  memcpy(REAL(P), internal->P, internal->dim_P * sizeof(double));
  SET_VECTOR_ELT(contents, 68, P);
  SEXP P_nV = PROTECT(allocVector(REALSXP, internal->dim_P_nV));
  memcpy(REAL(P_nV), internal->P_nV, internal->dim_P_nV * sizeof(double));
  SET_VECTOR_ELT(contents, 69, P_nV);
  SET_VECTOR_ELT(contents, 70, ScalarReal(internal->Pmin));
  SEXP R_new = PROTECT(allocVector(REALSXP, internal->dim_R_new));
  memcpy(REAL(R_new), internal->R_new, internal->dim_R_new * sizeof(double));
  SET_VECTOR_ELT(contents, 71, R_new);
  SET_VECTOR_ELT(contents, 72, ScalarReal(internal->R0));
  SEXP Rec0 = PROTECT(allocVector(REALSXP, internal->dim_Rec0));
  memcpy(REAL(Rec0), internal->Rec0, internal->dim_Rec0 * sizeof(double));
  SET_VECTOR_ELT(contents, 73, Rec0);
  SEXP Sus0 = PROTECT(allocVector(REALSXP, internal->dim_Sus0));
  memcpy(REAL(Sus0), internal->Sus0, internal->dim_Sus0 * sizeof(double));
  SET_VECTOR_ELT(contents, 74, Sus0);
  SET_VECTOR_ELT(contents, 75, ScalarReal(internal->t_incubation));
  SET_VECTOR_ELT(contents, 76, ScalarReal(internal->t_infectious));
  SET_VECTOR_ELT(contents, 77, ScalarReal(internal->t_latent));
  SEXP Vac0 = PROTECT(allocVector(REALSXP, internal->dim_Vac0));
  memcpy(REAL(Vac0), internal->Vac0, internal->dim_Vac0 * sizeof(double));
  SET_VECTOR_ELT(contents, 78, Vac0);
  SEXP vacc_rate = PROTECT(allocVector(REALSXP, internal->dim_vacc_rate));
  memcpy(REAL(vacc_rate), internal->vacc_rate, internal->dim_vacc_rate * sizeof(double));
  SET_VECTOR_ELT(contents, 79, vacc_rate);
  SEXP vacc_rate_annual = PROTECT(allocVector(REALSXP, internal->dim_vacc_rate_annual));
  memcpy(REAL(vacc_rate_annual), internal->vacc_rate_annual, internal->dim_vacc_rate_annual * sizeof(double));
  odin_set_dim(vacc_rate_annual, 2, internal->dim_vacc_rate_annual_1, internal->dim_vacc_rate_annual_2);
  SET_VECTOR_ELT(contents, 80, vacc_rate_annual);
  SET_VECTOR_ELT(contents, 81, ScalarReal(internal->vaccine_efficacy));
  SET_VECTOR_ELT(contents, 82, ScalarReal(internal->year0));
  SET_VECTOR_ELT(contents, 83, ScalarLogical(internal->SEIRV_Model_use_dde));
  SEXP nms = PROTECT(allocVector(STRSXP, 84));
  SET_STRING_ELT(nms, 0, mkChar("beta"));
  SET_STRING_ELT(nms, 1, mkChar("Cas0"));
  SET_STRING_ELT(nms, 2, mkChar("delay_ring_I_lag"));
  SET_STRING_ELT(nms, 3, mkChar("delay_ring_I_new"));
  SET_STRING_ELT(nms, 4, mkChar("delay_ring_R_new"));
  SET_STRING_ELT(nms, 5, mkChar("dim_C"));
  SET_STRING_ELT(nms, 6, mkChar("dim_Cas0"));
  SET_STRING_ELT(nms, 7, mkChar("dim_dP1"));
  SET_STRING_ELT(nms, 8, mkChar("dim_dP1_all"));
  SET_STRING_ELT(nms, 9, mkChar("dim_dP1_all_1"));
  SET_STRING_ELT(nms, 10, mkChar("dim_dP1_all_2"));
  SET_STRING_ELT(nms, 11, mkChar("dim_dP2"));
  SET_STRING_ELT(nms, 12, mkChar("dim_dP2_all"));
  SET_STRING_ELT(nms, 13, mkChar("dim_dP2_all_1"));
  SET_STRING_ELT(nms, 14, mkChar("dim_dP2_all_2"));
  SET_STRING_ELT(nms, 15, mkChar("dim_E"));
  SET_STRING_ELT(nms, 16, mkChar("dim_E_new"));
  SET_STRING_ELT(nms, 17, mkChar("dim_Exp0"));
  SET_STRING_ELT(nms, 18, mkChar("dim_I"));
  SET_STRING_ELT(nms, 19, mkChar("dim_I_lag"));
  SET_STRING_ELT(nms, 20, mkChar("dim_I_new"));
  SET_STRING_ELT(nms, 21, mkChar("dim_Inf0"));
  SET_STRING_ELT(nms, 22, mkChar("dim_inv_P"));
  SET_STRING_ELT(nms, 23, mkChar("dim_inv_P_nV"));
  SET_STRING_ELT(nms, 24, mkChar("dim_P"));
  SET_STRING_ELT(nms, 25, mkChar("dim_P_nV"));
  SET_STRING_ELT(nms, 26, mkChar("dim_R"));
  SET_STRING_ELT(nms, 27, mkChar("dim_R_new"));
  SET_STRING_ELT(nms, 28, mkChar("dim_Rec0"));
  SET_STRING_ELT(nms, 29, mkChar("dim_S"));
  SET_STRING_ELT(nms, 30, mkChar("dim_Sus0"));
  SET_STRING_ELT(nms, 31, mkChar("dim_V"));
  SET_STRING_ELT(nms, 32, mkChar("dim_Vac0"));
  SET_STRING_ELT(nms, 33, mkChar("dim_vacc_rate"));
  SET_STRING_ELT(nms, 34, mkChar("dim_vacc_rate_annual"));
  SET_STRING_ELT(nms, 35, mkChar("dim_vacc_rate_annual_1"));
  SET_STRING_ELT(nms, 36, mkChar("dim_vacc_rate_annual_2"));
  SET_STRING_ELT(nms, 37, mkChar("dP1"));
  SET_STRING_ELT(nms, 38, mkChar("dP1_all"));
  SET_STRING_ELT(nms, 39, mkChar("dP2"));
  SET_STRING_ELT(nms, 40, mkChar("dP2_all"));
  SET_STRING_ELT(nms, 41, mkChar("dt"));
  SET_STRING_ELT(nms, 42, mkChar("E_new"));
  SET_STRING_ELT(nms, 43, mkChar("Exp0"));
  SET_STRING_ELT(nms, 44, mkChar("FOI_max"));
  SET_STRING_ELT(nms, 45, mkChar("FOI_spillover"));
  SET_STRING_ELT(nms, 46, mkChar("I_lag"));
  SET_STRING_ELT(nms, 47, mkChar("I_new"));
  SET_STRING_ELT(nms, 48, mkChar("Inf0"));
  SET_STRING_ELT(nms, 49, mkChar("initial_C"));
  SET_STRING_ELT(nms, 50, mkChar("initial_day"));
  SET_STRING_ELT(nms, 51, mkChar("initial_E"));
  SET_STRING_ELT(nms, 52, mkChar("initial_FOI_total"));
  SET_STRING_ELT(nms, 53, mkChar("initial_I"));
  SET_STRING_ELT(nms, 54, mkChar("initial_R"));
  SET_STRING_ELT(nms, 55, mkChar("initial_S"));
  SET_STRING_ELT(nms, 56, mkChar("initial_step"));
  SET_STRING_ELT(nms, 57, mkChar("initial_V"));
  SET_STRING_ELT(nms, 58, mkChar("initial_year"));
  SET_STRING_ELT(nms, 59, mkChar("inv_P"));
  SET_STRING_ELT(nms, 60, mkChar("inv_P_nV"));
  SET_STRING_ELT(nms, 61, mkChar("N_age"));
  SET_STRING_ELT(nms, 62, mkChar("n_years"));
  SET_STRING_ELT(nms, 63, mkChar("offset_variable_C"));
  SET_STRING_ELT(nms, 64, mkChar("offset_variable_E"));
  SET_STRING_ELT(nms, 65, mkChar("offset_variable_I"));
  SET_STRING_ELT(nms, 66, mkChar("offset_variable_R"));
  SET_STRING_ELT(nms, 67, mkChar("offset_variable_V"));
  SET_STRING_ELT(nms, 68, mkChar("P"));
  SET_STRING_ELT(nms, 69, mkChar("P_nV"));
  SET_STRING_ELT(nms, 70, mkChar("Pmin"));
  SET_STRING_ELT(nms, 71, mkChar("R_new"));
  SET_STRING_ELT(nms, 72, mkChar("R0"));
  SET_STRING_ELT(nms, 73, mkChar("Rec0"));
  SET_STRING_ELT(nms, 74, mkChar("Sus0"));
  SET_STRING_ELT(nms, 75, mkChar("t_incubation"));
  SET_STRING_ELT(nms, 76, mkChar("t_infectious"));
  SET_STRING_ELT(nms, 77, mkChar("t_latent"));
  SET_STRING_ELT(nms, 78, mkChar("Vac0"));
  SET_STRING_ELT(nms, 79, mkChar("vacc_rate"));
  SET_STRING_ELT(nms, 80, mkChar("vacc_rate_annual"));
  SET_STRING_ELT(nms, 81, mkChar("vaccine_efficacy"));
  SET_STRING_ELT(nms, 82, mkChar("year0"));
  SET_STRING_ELT(nms, 83, mkChar("SEIRV_Model_use_dde"));
  setAttrib(contents, R_NamesSymbol, nms);
  UNPROTECT(28);
  return contents;
}
SEXP SEIRV_Model_set_user(SEXP internal_p, SEXP user) {
  SEIRV_Model_internal *internal = SEIRV_Model_get_internal(internal_p, 1);
  internal->dt = user_get_scalar_double(user, "dt", internal->dt, NA_REAL, NA_REAL);
  internal->FOI_spillover = user_get_scalar_double(user, "FOI_spillover", internal->FOI_spillover, NA_REAL, NA_REAL);
  internal->N_age = user_get_scalar_int(user, "N_age", internal->N_age, NA_REAL, NA_REAL);
  internal->n_years = user_get_scalar_int(user, "n_years", internal->n_years, NA_REAL, NA_REAL);
  internal->R0 = user_get_scalar_double(user, "R0", internal->R0, NA_REAL, NA_REAL);
  internal->vaccine_efficacy = user_get_scalar_double(user, "vaccine_efficacy", internal->vaccine_efficacy, NA_REAL, NA_REAL);
  internal->year0 = user_get_scalar_double(user, "year0", internal->year0, NA_REAL, NA_REAL);
  internal->beta = (internal->R0 * internal->dt) / (double) internal->t_infectious;
  internal->dim_C = internal->N_age;
  internal->dim_Cas0 = internal->N_age;
  internal->dim_dP1 = internal->N_age;
  internal->dim_dP1_all_1 = internal->N_age;
  internal->dim_dP1_all_2 = internal->n_years;
  internal->dim_dP2 = internal->N_age;
  internal->dim_dP2_all_1 = internal->N_age;
  internal->dim_dP2_all_2 = internal->n_years;
  internal->dim_E = internal->N_age;
  internal->dim_E_new = internal->N_age;
  internal->dim_Exp0 = internal->N_age;
  internal->dim_I = internal->N_age;
  internal->dim_I_lag = internal->N_age;
  internal->dim_I_new = internal->N_age;
  internal->dim_Inf0 = internal->N_age;
  internal->dim_inv_P = internal->N_age;
  internal->dim_inv_P_nV = internal->N_age;
  internal->dim_P = internal->N_age;
  internal->dim_P_nV = internal->N_age;
  internal->dim_R = internal->N_age;
  internal->dim_R_new = internal->N_age;
  internal->dim_Rec0 = internal->N_age;
  internal->dim_S = internal->N_age;
  internal->dim_Sus0 = internal->N_age;
  internal->dim_V = internal->N_age;
  internal->dim_Vac0 = internal->N_age;
  internal->dim_vacc_rate = internal->N_age;
  internal->dim_vacc_rate_annual_1 = internal->N_age;
  internal->dim_vacc_rate_annual_2 = internal->n_years;
  internal->initial_FOI_total = internal->FOI_spillover;
  internal->initial_year = internal->year0 - 1;
  R_Free(internal->dP1);
  internal->dP1 = (double*) R_Calloc(internal->dim_dP1, double);
  R_Free(internal->dP2);
  internal->dP2 = (double*) R_Calloc(internal->dim_dP2, double);
  R_Free(internal->E_new);
  internal->E_new = (double*) R_Calloc(internal->dim_E_new, double);
  R_Free(internal->I_lag);
  internal->I_lag = (double*) R_Calloc(internal->dim_I_lag, double);
  R_Free(internal->I_new);
  internal->I_new = (double*) R_Calloc(internal->dim_I_new, double);
  R_Free(internal->initial_C);
  internal->initial_C = (double*) R_Calloc(internal->dim_C, double);
  R_Free(internal->initial_E);
  internal->initial_E = (double*) R_Calloc(internal->dim_E, double);
  R_Free(internal->initial_I);
  internal->initial_I = (double*) R_Calloc(internal->dim_I, double);
  R_Free(internal->initial_R);
  internal->initial_R = (double*) R_Calloc(internal->dim_R, double);
  R_Free(internal->initial_S);
  internal->initial_S = (double*) R_Calloc(internal->dim_S, double);
  R_Free(internal->initial_V);
  internal->initial_V = (double*) R_Calloc(internal->dim_V, double);
  R_Free(internal->inv_P);
  internal->inv_P = (double*) R_Calloc(internal->dim_inv_P, double);
  R_Free(internal->inv_P_nV);
  internal->inv_P_nV = (double*) R_Calloc(internal->dim_inv_P_nV, double);
  R_Free(internal->P);
  internal->P = (double*) R_Calloc(internal->dim_P, double);
  R_Free(internal->P_nV);
  internal->P_nV = (double*) R_Calloc(internal->dim_P_nV, double);
  R_Free(internal->R_new);
  internal->R_new = (double*) R_Calloc(internal->dim_R_new, double);
  R_Free(internal->vacc_rate);
  internal->vacc_rate = (double*) R_Calloc(internal->dim_vacc_rate, double);
  internal->Cas0 = (double*) user_get_array(user, false, internal->Cas0, "Cas0", NA_REAL, NA_REAL, 1, internal->dim_Cas0);
  if (internal->delay_ring_I_lag) {
    ring_buffer_destroy(internal->delay_ring_I_lag);
  }
  internal->delay_ring_I_lag = ring_buffer_create(10000, internal->dim_I_lag * sizeof(double), OVERFLOW_OVERWRITE);
  if (internal->delay_ring_I_new) {
    ring_buffer_destroy(internal->delay_ring_I_new);
  }
  internal->delay_ring_I_new = ring_buffer_create(10000, internal->dim_I_new * sizeof(double), OVERFLOW_OVERWRITE);
  if (internal->delay_ring_R_new) {
    ring_buffer_destroy(internal->delay_ring_R_new);
  }
  internal->delay_ring_R_new = ring_buffer_create(10000, internal->dim_R_new * sizeof(double), OVERFLOW_OVERWRITE);
  internal->dim_dP1_all = internal->dim_dP1_all_1 * internal->dim_dP1_all_2;
  internal->dim_dP2_all = internal->dim_dP2_all_1 * internal->dim_dP2_all_2;
  internal->dim_vacc_rate_annual = internal->dim_vacc_rate_annual_1 * internal->dim_vacc_rate_annual_2;
  internal->Exp0 = (double*) user_get_array(user, false, internal->Exp0, "Exp0", NA_REAL, NA_REAL, 1, internal->dim_Exp0);
  internal->Inf0 = (double*) user_get_array(user, false, internal->Inf0, "Inf0", NA_REAL, NA_REAL, 1, internal->dim_Inf0);
  internal->offset_variable_C = internal->dim_E + internal->dim_I + internal->dim_R + internal->dim_S + internal->dim_V + 3;
  internal->offset_variable_E = internal->dim_S + 3;
  internal->offset_variable_I = internal->dim_E + internal->dim_S + 3;
  internal->offset_variable_R = internal->dim_E + internal->dim_I + internal->dim_S + 3;
  internal->offset_variable_V = internal->dim_E + internal->dim_I + internal->dim_R + internal->dim_S + 3;
  internal->Rec0 = (double*) user_get_array(user, false, internal->Rec0, "Rec0", NA_REAL, NA_REAL, 1, internal->dim_Rec0);
  internal->Sus0 = (double*) user_get_array(user, false, internal->Sus0, "Sus0", NA_REAL, NA_REAL, 1, internal->dim_Sus0);
  internal->Vac0 = (double*) user_get_array(user, false, internal->Vac0, "Vac0", NA_REAL, NA_REAL, 1, internal->dim_Vac0);
  internal->dP1_all = (double*) user_get_array(user, false, internal->dP1_all, "dP1_all", NA_REAL, NA_REAL, 2, internal->dim_dP1_all_1, internal->dim_dP1_all_2);
  internal->dP2_all = (double*) user_get_array(user, false, internal->dP2_all, "dP2_all", NA_REAL, NA_REAL, 2, internal->dim_dP2_all_1, internal->dim_dP2_all_2);
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->initial_C[i - 1] = internal->Cas0[i - 1];
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->initial_E[i - 1] = internal->Exp0[i - 1];
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->initial_I[i - 1] = internal->Inf0[i - 1];
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->initial_R[i - 1] = internal->Rec0[i - 1];
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->initial_S[i - 1] = internal->Sus0[i - 1];
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->initial_V[i - 1] = internal->Vac0[i - 1];
  }
  internal->vacc_rate_annual = (double*) user_get_array(user, false, internal->vacc_rate_annual, "vacc_rate_annual", NA_REAL, NA_REAL, 2, internal->dim_vacc_rate_annual_1, internal->dim_vacc_rate_annual_2);
  return R_NilValue;
}
SEXP SEIRV_Model_set_initial(SEXP internal_p, SEXP step_ptr, SEXP state_ptr) {
  SEIRV_Model_internal *internal = SEIRV_Model_get_internal(internal_p, 1);
  const double step = REAL(step_ptr)[0];
  internal->initial_step = step;
  if (state_ptr != R_NilValue) {
    double * state = REAL(state_ptr);
    internal->initial_day = state[0];
    internal->initial_year = state[1];
    internal->initial_FOI_total = state[2];
    memcpy(internal->initial_S, state + 3, internal->dim_S * sizeof(double));
    memcpy(internal->initial_E, state + internal->offset_variable_E, internal->dim_E * sizeof(double));
    memcpy(internal->initial_I, state + internal->offset_variable_I, internal->dim_I * sizeof(double));
    memcpy(internal->initial_R, state + internal->offset_variable_R, internal->dim_R * sizeof(double));
    memcpy(internal->initial_V, state + internal->offset_variable_V, internal->dim_V * sizeof(double));
    memcpy(internal->initial_C, state + internal->offset_variable_C, internal->dim_C * sizeof(double));
  }
  return R_NilValue;
}
SEXP SEIRV_Model_metadata(SEXP internal_p) {
  SEIRV_Model_internal *internal = SEIRV_Model_get_internal(internal_p, 1);
  SEXP ret = PROTECT(allocVector(VECSXP, 4));
  SEXP nms = PROTECT(allocVector(STRSXP, 4));
  SET_STRING_ELT(nms, 0, mkChar("variable_order"));
  SET_STRING_ELT(nms, 1, mkChar("output_order"));
  SET_STRING_ELT(nms, 2, mkChar("n_out"));
  SET_STRING_ELT(nms, 3, mkChar("interpolate_t"));
  setAttrib(ret, R_NamesSymbol, nms);
  SEXP variable_length = PROTECT(allocVector(VECSXP, 9));
  SEXP variable_names = PROTECT(allocVector(STRSXP, 9));
  setAttrib(variable_length, R_NamesSymbol, variable_names);
  SET_VECTOR_ELT(variable_length, 0, R_NilValue);
  SET_VECTOR_ELT(variable_length, 1, R_NilValue);
  SET_VECTOR_ELT(variable_length, 2, R_NilValue);
  SET_VECTOR_ELT(variable_length, 3, ScalarInteger(internal->dim_S));
  SET_VECTOR_ELT(variable_length, 4, ScalarInteger(internal->dim_E));
  SET_VECTOR_ELT(variable_length, 5, ScalarInteger(internal->dim_I));
  SET_VECTOR_ELT(variable_length, 6, ScalarInteger(internal->dim_R));
  SET_VECTOR_ELT(variable_length, 7, ScalarInteger(internal->dim_V));
  SET_VECTOR_ELT(variable_length, 8, ScalarInteger(internal->dim_C));
  SET_STRING_ELT(variable_names, 0, mkChar("day"));
  SET_STRING_ELT(variable_names, 1, mkChar("year"));
  SET_STRING_ELT(variable_names, 2, mkChar("FOI_total"));
  SET_STRING_ELT(variable_names, 3, mkChar("S"));
  SET_STRING_ELT(variable_names, 4, mkChar("E"));
  SET_STRING_ELT(variable_names, 5, mkChar("I"));
  SET_STRING_ELT(variable_names, 6, mkChar("R"));
  SET_STRING_ELT(variable_names, 7, mkChar("V"));
  SET_STRING_ELT(variable_names, 8, mkChar("C"));
  SET_VECTOR_ELT(ret, 0, variable_length);
  UNPROTECT(2);
  SET_VECTOR_ELT(ret, 1, R_NilValue);
  SET_VECTOR_ELT(ret, 2, ScalarInteger(0));
  UNPROTECT(2);
  return ret;
}
SEXP SEIRV_Model_initial_conditions(SEXP internal_p, SEXP step_ptr) {
  int step = scalar_int(step_ptr, "step");
  SEIRV_Model_internal *internal = SEIRV_Model_get_internal(internal_p, 1);
  SEXP r_state = PROTECT(allocVector(REALSXP, internal->dim_C + internal->dim_E + internal->dim_I + internal->dim_R + internal->dim_S + internal->dim_V + 3));
  double * state = REAL(r_state);
  state[0] = internal->initial_day;
  state[1] = internal->initial_year;
  state[2] = internal->initial_FOI_total;
  memcpy(state + 3, internal->initial_S, internal->dim_S * sizeof(double));
  memcpy(state + internal->offset_variable_E, internal->initial_E, internal->dim_E * sizeof(double));
  memcpy(state + internal->offset_variable_I, internal->initial_I, internal->dim_I * sizeof(double));
  memcpy(state + internal->offset_variable_R, internal->initial_R, internal->dim_R * sizeof(double));
  memcpy(state + internal->offset_variable_V, internal->initial_V, internal->dim_V * sizeof(double));
  memcpy(state + internal->offset_variable_C, internal->initial_C, internal->dim_C * sizeof(double));
  UNPROTECT(1);
  return r_state;
}
void SEIRV_Model_rhs(SEIRV_Model_internal* internal, size_t step, double * state, double * state_next, double * output) {
  double day = state[0];
  double * S = state + 3;
  double * E = state + internal->offset_variable_E;
  double * I = state + internal->offset_variable_I;
  double * R = state + internal->offset_variable_R;
  double * V = state + internal->offset_variable_V;
  state_next[0] = day + internal->dt;
  double year_i = floor(((step + 1) * internal->dt) / (double) 365) + 1;
  state_next[1] = year_i + internal->year0 - 1;
  double * delay_ring_I_lag_head = (double*) ring_buffer_head(internal->delay_ring_I_lag);
  for (int i = 1; i <= internal->N_age; ++i) {
    delay_ring_I_lag_head[i - 1] = I[i - 1];
  }
  ring_buffer_head_advance(internal->delay_ring_I_lag);
  double * delay_ring_I_lag_tail;
  if ((int)step - internal->t_incubation <= internal->initial_step) {
    delay_ring_I_lag_tail = (double*)ring_buffer_tail(internal->delay_ring_I_lag);
  } else {
    delay_ring_I_lag_tail = (double*) ring_buffer_head_offset(internal->delay_ring_I_lag, internal->t_incubation);
  }
  memcpy(internal->I_lag, delay_ring_I_lag_tail, internal->dim_I_lag * sizeof(double));
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->P_nV[i - 1] = S[i - 1] + R[i - 1];
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->dP1[i - 1] = internal->dP1_all[internal->dim_dP1_all_1 * ((int) (year_i) - 1) + i - 1] * internal->dt;
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->dP2[i - 1] = internal->dP2_all[internal->dim_dP2_all_1 * ((int) (year_i) - 1) + i - 1] * internal->dt;
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->inv_P_nV[i - 1] = 1 / (double) internal->P_nV[i - 1];
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->P[i - 1] = internal->P_nV[i - 1] + V[i - 1];
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->inv_P[i - 1] = 1 / (double) internal->P[i - 1];
  }
  double P_tot = odin_sum1(internal->P, 0, internal->dim_P);
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->vacc_rate[i - 1] = internal->vacc_rate_annual[internal->dim_vacc_rate_annual_1 * ((int) (year_i) - 1) + i - 1] * internal->vaccine_efficacy * internal->dt * internal->P[i - 1];
  }
  double FOI_sum = fmin(internal->FOI_max, internal->beta * (odin_sum1(internal->I_lag, 0, internal->dim_I_lag) / (double) P_tot) + (internal->FOI_spillover * internal->dt));
  {
     int i = 1;
     state_next[internal->offset_variable_V + i - 1] = fmax(internal->Pmin, V[0] + internal->vacc_rate[0] - (internal->dP2[0] * V[0] * internal->inv_P[0]));
  }
  for (int i = 2; i <= internal->N_age; ++i) {
    state_next[internal->offset_variable_V + i - 1] = fmax(internal->Pmin, V[i - 1] + internal->vacc_rate[i - 1] + (internal->dP1[i - 1] * V[i - 1 - 1] * internal->inv_P[i - 1 - 1]) - (internal->dP2[i - 1] * V[i - 1] * internal->inv_P[i - 1]));
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    internal->E_new[i - 1] = S[i - 1] * FOI_sum;
  }
  state_next[2] = FOI_sum;
  double * delay_ring_I_new_head = (double*) ring_buffer_head(internal->delay_ring_I_new);
  for (int i = 1; i <= internal->N_age; ++i) {
    delay_ring_I_new_head[i - 1] = internal->E_new[i - 1];
  }
  ring_buffer_head_advance(internal->delay_ring_I_new);
  double * delay_ring_I_new_tail;
  if ((int)step - internal->t_latent <= internal->initial_step) {
    delay_ring_I_new_tail = (double*)ring_buffer_tail(internal->delay_ring_I_new);
  } else {
    delay_ring_I_new_tail = (double*) ring_buffer_head_offset(internal->delay_ring_I_new, internal->t_latent);
  }
  memcpy(internal->I_new, delay_ring_I_new_tail, internal->dim_I_new * sizeof(double));
  {
     int i = 1;
     state_next[3 + i - 1] = fmax(internal->Pmin, S[0] - internal->E_new[0] - internal->vacc_rate[0] * S[0] * internal->inv_P_nV[0] + internal->dP1[0] - (internal->dP2[0] * S[0] * internal->inv_P[0]));
  }
  for (int i = 2; i <= internal->N_age; ++i) {
    state_next[3 + i - 1] = fmax(internal->Pmin, S[i - 1] - internal->E_new[i - 1] - internal->vacc_rate[i - 1] * S[i - 1] * internal->inv_P_nV[i - 1] + (internal->dP1[i - 1] * S[i - 1 - 1] * internal->inv_P[i - 1 - 1]) - (internal->dP2[i - 1] * S[i - 1] * internal->inv_P[i - 1]));
  }
  double * delay_ring_R_new_head = (double*) ring_buffer_head(internal->delay_ring_R_new);
  for (int i = 1; i <= internal->N_age; ++i) {
    delay_ring_R_new_head[i - 1] = internal->I_new[i - 1];
  }
  ring_buffer_head_advance(internal->delay_ring_R_new);
  double * delay_ring_R_new_tail;
  if ((int)step - internal->t_infectious <= internal->initial_step) {
    delay_ring_R_new_tail = (double*)ring_buffer_tail(internal->delay_ring_R_new);
  } else {
    delay_ring_R_new_tail = (double*) ring_buffer_head_offset(internal->delay_ring_R_new, internal->t_infectious);
  }
  memcpy(internal->R_new, delay_ring_R_new_tail, internal->dim_R_new * sizeof(double));
  for (int i = 1; i <= internal->N_age; ++i) {
    state_next[internal->offset_variable_C + i - 1] = internal->I_new[i - 1];
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    state_next[internal->offset_variable_E + i - 1] = fmax(internal->Pmin, E[i - 1] + internal->E_new[i - 1] - internal->I_new[i - 1]);
  }
  for (int i = 1; i <= internal->N_age; ++i) {
    state_next[internal->offset_variable_I + i - 1] = fmax(internal->Pmin, I[i - 1] + internal->I_new[i - 1] - internal->R_new[i - 1]);
  }
  {
     int i = 1;
     state_next[internal->offset_variable_R + i - 1] = fmax(internal->Pmin, R[0] + internal->R_new[0] - internal->vacc_rate[0] * R[0] * internal->inv_P_nV[0] - (internal->dP2[0] * R[0] * internal->inv_P[0]));
  }
  for (int i = 2; i <= internal->N_age; ++i) {
    state_next[internal->offset_variable_R + i - 1] = fmax(internal->Pmin, R[i - 1] + internal->R_new[i - 1] - internal->vacc_rate[i - 1] * R[i - 1] * internal->inv_P_nV[i - 1] + (internal->dP1[i - 1] * R[i - 1 - 1] * internal->inv_P[i - 1 - 1]) - (internal->dP2[i - 1] * R[i - 1] * internal->inv_P[i - 1]));
  }
}
void SEIRV_Model_rhs_dde(size_t n_eq, size_t step, double * state, double * state_next, size_t n_out, double * output, void * internal) {
  SEIRV_Model_rhs((SEIRV_Model_internal*)internal, step, state, state_next, output);
}
SEXP SEIRV_Model_rhs_r(SEXP internal_p, SEXP step, SEXP state) {
  Rf_error("Can't call update() on delay models");
  return R_NilValue;
}
double user_get_scalar_double(SEXP user, const char *name,
                              double default_value, double min, double max) {
  double ret = default_value;
  SEXP el = user_list_element(user, name);
  if (el != R_NilValue) {
    if (length(el) != 1) {
      Rf_error("Expected a scalar numeric for '%s'", name);
    }
    if (TYPEOF(el) == REALSXP) {
      ret = REAL(el)[0];
    } else if (TYPEOF(el) == INTSXP) {
      ret = INTEGER(el)[0];
    } else {
      Rf_error("Expected a numeric value for '%s'", name);
    }
  }
  if (ISNA(ret)) {
    Rf_error("Expected a value for '%s'", name);
  }
  user_check_values_double(&ret, 1, min, max, name);
  return ret;
}
int user_get_scalar_int(SEXP user, const char *name,
                        int default_value, double min, double max) {
  int ret = default_value;
  SEXP el = user_list_element(user, name);
  if (el != R_NilValue) {
    if (length(el) != 1) {
      Rf_error("Expected scalar integer for '%d'", name);
    }
    if (TYPEOF(el) == REALSXP) {
      double tmp = REAL(el)[0];
      if (fabs(tmp - round(tmp)) > 2e-8) {
        Rf_error("Expected '%s' to be integer-like", name);
      }
    }
    ret = INTEGER(coerceVector(el, INTSXP))[0];
  }
  if (ret == NA_INTEGER) {
    Rf_error("Expected a value for '%s'", name);
  }
  user_check_values_int(&ret, 1, min, max, name);
  return ret;
}
void user_check_values_double(double * value, size_t len,
                                  double min, double max, const char *name) {
  for (size_t i = 0; i < len; ++i) {
    if (ISNA(value[i])) {
      Rf_error("'%s' must not contain any NA values", name);
    }
  }
  if (min != NA_REAL) {
    for (size_t i = 0; i < len; ++i) {
      if (value[i] < min) {
        Rf_error("Expected '%s' to be at least %g", name, min);
      }
    }
  }
  if (max != NA_REAL) {
    for (size_t i = 0; i < len; ++i) {
      if (value[i] > max) {
        Rf_error("Expected '%s' to be at most %g", name, max);
      }
    }
  }
}
void user_check_values_int(int * value, size_t len,
                               double min, double max, const char *name) {
  for (size_t i = 0; i < len; ++i) {
    if (ISNA(value[i])) {
      Rf_error("'%s' must not contain any NA values", name);
    }
  }
  if (min != NA_REAL) {
    for (size_t i = 0; i < len; ++i) {
      if (value[i] < min) {
        Rf_error("Expected '%s' to be at least %g", name, min);
      }
    }
  }
  if (max != NA_REAL) {
    for (size_t i = 0; i < len; ++i) {
      if (value[i] > max) {
        Rf_error("Expected '%s' to be at most %g", name, max);
      }
    }
  }
}
void user_check_values(SEXP value, double min, double max,
                           const char *name) {
  size_t len = (size_t)length(value);
  if (TYPEOF(value) == INTSXP) {
    user_check_values_int(INTEGER(value), len, min, max, name);
  } else {
    user_check_values_double(REAL(value), len, min, max, name);
  }
}
SEXP user_list_element(SEXP list, const char *name) {
  SEXP ret = R_NilValue, names = getAttrib(list, R_NamesSymbol);
  for (int i = 0; i < length(list); ++i) {
    if (strcmp(CHAR(STRING_ELT(names, i)), name) == 0) {
      ret = VECTOR_ELT(list, i);
      break;
    }
  }
  return ret;
}
void odin_set_dim(SEXP target, int rank, ...) {
  SEXP r_dim = PROTECT(allocVector(INTSXP, rank));
  int *dim = INTEGER(r_dim);

  va_list ap;
  va_start(ap, rank);
  for (size_t i = 0; i < (size_t)rank; ++i) {
    dim[i] = va_arg(ap, int);
  }
  va_end(ap);

  setAttrib(target, R_DimSymbol, r_dim);
  UNPROTECT(1);
}
void* user_get_array_dim(SEXP user, bool is_integer, void * previous,
                         const char *name, int rank,
                         double min, double max, int *dest_dim) {
  SEXP el = user_get_array_check_rank(user, name, rank, previous == NULL);
  if (el == R_NilValue) {
    return previous;
  }

  dest_dim[0] = LENGTH(el);
  if (rank > 1) {
    SEXP r_dim = PROTECT(coerceVector(getAttrib(el, R_DimSymbol), INTSXP));
    int *dim = INTEGER(r_dim);

    for (size_t i = 0; i < (size_t) rank; ++i) {
      dest_dim[i + 1] = dim[i];
    }

    UNPROTECT(1);
  }

  el = PROTECT(user_get_array_check(el, is_integer, name, min, max));

  int len = LENGTH(el);
  void *dest = NULL;
  if (is_integer) {
    dest = R_Calloc(len, int);
    memcpy(dest, INTEGER(el), len * sizeof(int));
  } else {
    dest = R_Calloc(len, double);
    memcpy(dest, REAL(el), len * sizeof(double));
  }
  R_Free(previous);

  UNPROTECT(1);

  return dest;
}
void* user_get_array(SEXP user, bool is_integer, void * previous,
                     const char *name, double min, double max,
                     int rank, ...) {
  SEXP el = user_get_array_check_rank(user, name, rank, previous == NULL);
  if (el == R_NilValue) {
    return previous;
  }

  SEXP r_dim;
  int *dim;

  size_t len = LENGTH(el);
  if (rank == 1) {
    r_dim = PROTECT(ScalarInteger(len));
  } else {
    r_dim = PROTECT(coerceVector(getAttrib(el, R_DimSymbol), INTSXP));
  }
  dim = INTEGER(r_dim);

  va_list ap;
  va_start(ap, rank);
  for (size_t i = 0; i < (size_t) rank; ++i) {
    int dim_expected = va_arg(ap, int);
    if (dim[i] != dim_expected) {
      va_end(ap); // avoid a leak
      if (rank == 1) {
        Rf_error("Expected length %d value for '%s'", dim_expected, name);
      } else {
        Rf_error("Incorrect size of dimension %d of '%s' (expected %d)",
                 i + 1, name, dim_expected);
      }
    }
  }
  va_end(ap);
  UNPROTECT(1);

  el = PROTECT(user_get_array_check(el, is_integer, name, min, max));

  void *dest = NULL;
  if (is_integer) {
    dest = R_Calloc(len, int);
    memcpy(dest, INTEGER(el), len * sizeof(int));
  } else {
    dest = R_Calloc(len, double);
    memcpy(dest, REAL(el), len * sizeof(double));
  }
  R_Free(previous);

  UNPROTECT(1);

  return dest;
}
SEXP user_get_array_check(SEXP el, bool is_integer, const char *name,
                          double min, double max) {
  size_t len = (size_t) length(el);
  if (is_integer) {
    if (TYPEOF(el) == INTSXP) {
      user_check_values_int(INTEGER(el), len, min, max, name);
    } else if (TYPEOF(el) == REALSXP) {
      el = PROTECT(coerceVector(el, INTSXP));
      user_check_values_int(INTEGER(el), len, min, max, name);
      UNPROTECT(1);
    } else {
      Rf_error("Expected a integer value for '%s'", name);
    }
  } else {
    if (TYPEOF(el) == INTSXP) {
      el = PROTECT(coerceVector(el, REALSXP));
      user_check_values_double(REAL(el), len, min, max, name);
      UNPROTECT(1);
    } else if (TYPEOF(el) == REALSXP) {
      user_check_values_double(REAL(el), len, min, max, name);
    } else {
      Rf_error("Expected a numeric value for '%s'", name);
    }
  }
  return el;
}
SEXP user_get_array_check_rank(SEXP user, const char *name, int rank,
                               bool required) {
  SEXP el = user_list_element(user, name);
  if (el == R_NilValue) {
    if (required) {
      Rf_error("Expected a value for '%s'", name);
    }
  } else {
    if (rank == 1) {
      if (isArray(el)) {
        Rf_error("Expected a numeric vector for '%s'", name);
      }
    } else {
      SEXP r_dim = getAttrib(el, R_DimSymbol);
      if (r_dim == R_NilValue || LENGTH(r_dim) != rank) {
        if (rank == 2) {
          Rf_error("Expected a numeric matrix for '%s'", name);
        } else {
          Rf_error("Expected a numeric array of rank %d for '%s'", rank, name);
        }
      }
    }
  }
  return el;
}
double odin_sum1(double *x, size_t from, size_t to) {
  double tot = 0.0;
  for (size_t i = from; i < to; ++i) {
    tot += x[i];
  }
  return tot;
}
int odin_isum1(int *x, size_t from, size_t to) {
  int tot = 0.0;
  for (size_t i = from; i < to; ++i) {
    tot += x[i];
  }
  return tot;
}
int scalar_int(SEXP x, const char * name) {
  if (Rf_length(x) != 1) {
    Rf_error("Expected a scalar for '%s'", name);
  }
  int ret = 0;
  if (TYPEOF(x) == INTSXP) {
    ret = INTEGER(x)[0];
  } else if (TYPEOF(x) == REALSXP) {
    double rx = REAL(x)[0];
    ret = rx;
    if (fabs(rx - ret) > sqrt(DBL_EPSILON)) {
      Rf_error("Expected a integer-like for '%s'", name);
    }
  } else {
    Rf_error("Expected an integer value for '%s'", name);
  }
  return ret;
}
#ifndef _RING_H_
#endif

// Some prototypes used here that aren't public:
bool ring_buffer_handle_overflow(ring_buffer *buffer, size_t n);
const data_t * ring_buffer_end(const ring_buffer *buffer);
data_t * ring_buffer_nextp(ring_buffer *buffer, const data_t *p);
size_t imin(size_t a, size_t b);

#ifdef RING_USE_STDLIB_ALLOC
#else
#endif

ring_buffer * ring_buffer_create(size_t size, size_t stride,
                                 overflow_action on_overflow) {
  const size_t bytes_data = (size + 1) * stride;
#ifdef RING_USE_STDLIB_ALLOC
  ring_buffer * buffer = (ring_buffer*) calloc(1, sizeof(ring_buffer));
  if (buffer == NULL) {
    return NULL;
  }
  buffer->data = (data_t*) calloc(bytes_data, 1);
  if (buffer->data == NULL) {
    free(buffer);
    return NULL;
  }
#else
  ring_buffer * buffer = (ring_buffer*) Calloc(1, ring_buffer);
  buffer->data = (data_t*) Calloc(bytes_data, data_t);
#endif
  buffer->size = size;
  buffer->stride = stride;
  buffer->bytes_data = bytes_data;
  buffer->on_overflow = on_overflow;
  ring_buffer_reset(buffer, false);
  return buffer;
}

void ring_buffer_destroy(ring_buffer *buffer) {
  if (buffer) {
#ifdef RING_USE_STDLIB_ALLOC
    free(buffer->data);
    free(buffer);
#else
    Free(buffer->data);
    Free(buffer);
#endif
    buffer = NULL;
  }
}

ring_buffer * ring_buffer_duplicate(const ring_buffer *buffer) {
  ring_buffer *ret = ring_buffer_create(buffer->size, buffer->stride,
                                        buffer->on_overflow);
#ifdef RING_USE_STDLIB_ALLOC
  if (ret == NULL) {
    return NULL;
  }
#endif
  ring_buffer_mirror(buffer, ret);
  return ret;
}

#define LOG_PHI 0.481211825028767
void ring_buffer_grow(ring_buffer *buffer, size_t n, bool exact) {
  if (n == 0) {
    return;
  }
  const size_t
    curr_size = ring_buffer_size(buffer, false),
    head_pos = ring_buffer_head_pos(buffer, true),
    tail_pos = ring_buffer_tail_pos(buffer, true);

  size_t size;
  if (exact) {
    size = curr_size + n;
  } else {
    const size_t curr_used = ring_buffer_used(buffer, false);
    const double r = (double) (curr_used + n) / (double) curr_size;
    if (r <= 1) {
      // Refuse to shrink the buffer:
      return;
    }
    size = ceil(curr_size * exp(ceil(log(r) / LOG_PHI) * LOG_PHI));
  }
  const size_t bytes_data = (size + 1) * buffer->stride;

#ifdef RING_USE_STDLIB_ALLOC
  void *tmp = realloc(buffer->data, bytes_data);
  if (tmp != NULL) {
    buffer->data = (data_t*) tmp;
  } else {
    // Out of memory.
#ifdef USING_R
    // Probably the most polite thing to do; could cause a memory leak
    // or leave things in a fairly inconsistent state.
    Rf_error("Ran out of memory while resizing ring buffer");
#else
    // This should cause a crash pretty quickly
    buffer->data = NULL;
#endif
  }
#else
  // R will handle the crash here for us:
  buffer->data = (data_t*) Realloc(buffer->data, bytes_data, data_t);
#endif
  // Ensure that all newly allocated data is zeroed
  const size_t len = (curr_size + 1) * buffer->stride;
  memset(buffer->data + len, 0, bytes_data - len);
  // And then correctly reset all the pointers
  buffer->head = buffer->data + head_pos;
  buffer->tail = buffer->data + tail_pos;
  buffer->size = size;
  buffer->bytes_data = bytes_data;
}

// Below here, nothing else should vary on RING_USE_STDLIB_ALLOC,
// though there is one dependency on USING_R

void ring_buffer_reset(ring_buffer *buffer, bool clear) {
  buffer->head = buffer->tail = buffer->data;
  if (clear) {
    memset(buffer->data, 0, buffer->bytes_data);
  }
}

size_t ring_buffer_size(const ring_buffer *buffer, bool bytes) {
  return bytes ? buffer->bytes_data - buffer->stride : buffer->size;
}

size_t ring_buffer_free(const ring_buffer *buffer, bool bytes) {
  size_t diff;
  if (buffer->head >= buffer->tail) {
    diff = ring_buffer_size(buffer, true) - (buffer->head - buffer->tail);
  } else {
    diff = buffer->tail - buffer->head - buffer->stride;
  }
  return bytes ? diff : diff / buffer->stride;
}

size_t ring_buffer_used(const ring_buffer *buffer, bool bytes) {
  return ring_buffer_size(buffer, bytes) - ring_buffer_free(buffer, bytes);
}

size_t ring_buffer_bytes_data(const ring_buffer *buffer) {
  return buffer->bytes_data;
}

bool ring_buffer_is_full(const ring_buffer *buffer) {
  return ring_buffer_free(buffer, true) == 0;
}

bool ring_buffer_is_empty(const ring_buffer *buffer) {
  return ring_buffer_free(buffer, true) == ring_buffer_size(buffer, true);
}

size_t ring_buffer_head_pos(const ring_buffer *buffer, bool bytes) {
  const size_t diff = buffer->head - buffer->data;
  return bytes ? diff : diff / buffer->stride;
}
size_t ring_buffer_tail_pos(const ring_buffer *buffer, bool bytes) {
  const size_t diff = buffer->tail - buffer->data;
  return bytes ? diff : diff / buffer->stride;
}

const void * ring_buffer_head(const ring_buffer *buffer) {
  return buffer->head;
}
const void * ring_buffer_tail(const ring_buffer *buffer) {
  return buffer->tail;
}
const void * ring_buffer_data(const ring_buffer *buffer) {
  return buffer->data;
}

size_t ring_buffer_set(ring_buffer *buffer, data_t c, size_t n) {
  if (buffer->on_overflow == OVERFLOW_OVERWRITE) {
    n = imin(n, ring_buffer_size(buffer, false) + 1);
  }
  const bool overflow = ring_buffer_handle_overflow(buffer, n);
  size_t nwritten = 0, nbytes = n * buffer->stride;
  const data_t *bufend = ring_buffer_end(buffer);

  while (nwritten != nbytes) {
    // don't copy beyond the end of the buffer
    const size_t n = imin(bufend - buffer->head, nbytes - nwritten);
    memset(buffer->head, c, n);
    buffer->head += n;
    nwritten += n;

    // wrap?
    if (buffer->head == bufend) {
      buffer->head = buffer->data;
    }
  }

  if (overflow) {
    buffer->tail = ring_buffer_nextp(buffer, buffer->head);
  }

  return nwritten;
}

// A downside of the current approach here is that we will go through
// the overflow check function n times.
size_t ring_buffer_set_stride(ring_buffer *buffer, const void *x, size_t n) {
  if (buffer->on_overflow == OVERFLOW_OVERWRITE) {
    n = imin(n, ring_buffer_size(buffer, false));
  } else {
    ring_buffer_handle_overflow(buffer, n);
  }
  for (size_t i = 0; i < n; ++i) {
    ring_buffer_push(buffer, x, 1);
  }
  return n;
}

const void * ring_buffer_push(ring_buffer *buffer, const void *src, size_t n) {
  const size_t overflow = ring_buffer_handle_overflow(buffer, n);
  const size_t nbytes = n * buffer->stride;
  const data_t *source = (const data_t*)src;
  const data_t *bufend = ring_buffer_end(buffer);
  size_t nread = 0;
  while (nread != nbytes) {
    size_t n = imin(bufend - buffer->head, nbytes - nread);
    memcpy(buffer->head, source + nread, n);
    buffer->head += n;
    nread += n;

    if (buffer->head == bufend) {
      buffer->head = buffer->data;
    }
  }

  if (overflow) {
    buffer->tail = ring_buffer_nextp(buffer, buffer->head);
  }
  return buffer->head;
}

const void * ring_buffer_take(ring_buffer *buffer, void *dest, size_t n) {
  const void * tail = ring_buffer_read(buffer, dest, n);
  if (tail != 0) {
    buffer->tail = buffer->data + ((data_t*)tail - buffer->data);
  }
  return tail;
}

const void * ring_buffer_read(const ring_buffer *buffer, void *dest, size_t n) {
  size_t bytes_used = ring_buffer_used(buffer, true);
  size_t nbytes = n * buffer->stride;
  if (nbytes > bytes_used) {
    return NULL;
  }
  const data_t *tail = buffer->tail;
  const data_t *bufend = ring_buffer_end(buffer);
  size_t nwritten = 0;
  while (nwritten != nbytes) {
    size_t n = imin(bufend - tail, nbytes - nwritten);
    memcpy((data_t*)dest + nwritten, tail, n);
    tail += n;
    nwritten += n;
    if (tail == bufend) {
      tail = buffer->data;
    }
  }
  return tail;
}

const void * ring_buffer_take_head(ring_buffer *buffer, void *dest, size_t n) {
  const void * head = ring_buffer_read_head(buffer, dest, n);
  if (head != 0) {
    buffer->head = buffer->data + ((data_t*)head - buffer->data);
  }
  return head;
}

const void * ring_buffer_read_head(const ring_buffer *buffer, void *dest,
                                   size_t n) {
  const size_t bytes_used = ring_buffer_used(buffer, true);
  const size_t nbytes = n * buffer->stride;
  if (nbytes > bytes_used) {
    return NULL;
  }
  const data_t *head = buffer->head;
  const data_t *bufend = ring_buffer_end(buffer);
  data_t *dest_data = (data_t*) dest; // cast so pointer arithmetic works

  for (size_t nwritten = 0; nwritten < n; ++nwritten) {
    if (head == buffer->data) {
      head = bufend;
    }
    head -= buffer->stride;
    memcpy((void*)dest_data, head, buffer->stride);
    dest_data += buffer->stride;
  }

  return head;
}

const void * ring_buffer_copy(ring_buffer *src, ring_buffer *dest, size_t n) {
  const size_t src_bytes_used = ring_buffer_used(src, true);
  const size_t nbytes = n * src->stride;
  if (src == dest || src->stride != dest->stride || nbytes > src_bytes_used) {
    return NULL;
  }
  const bool overflow = ring_buffer_handle_overflow(dest, n);

  const data_t *src_bufend = ring_buffer_end(src);
  const data_t *dest_bufend = ring_buffer_end(dest);
  size_t ncopied = 0;
  while (ncopied != nbytes) {
    size_t nsrc = imin(src_bufend - src->tail, nbytes - ncopied);
    size_t n = imin(dest_bufend - dest->head, nsrc);
    memcpy(dest->head, src->tail, n);
    src->tail += n;
    dest->head += n;
    ncopied += n;

    // wrap?
    if (src->tail == src_bufend) {
      src->tail = src->data;
    }
    if (dest->head == dest_bufend) {
      dest->head = dest->data;
    }
  }

  if (overflow) {
    dest->tail = ring_buffer_nextp(dest, dest->head);
  }

  return dest->head;
}

bool ring_buffer_mirror(const ring_buffer *src, ring_buffer *dest) {
  const bool ok = src != dest &&
    src->size == dest->size && src->stride == dest->stride;
  if (ok) {
    memcpy(dest->data, src->data, dest->bytes_data);
    dest->head = dest->data + ring_buffer_head_pos(src, true);
    dest->tail = dest->data + ring_buffer_tail_pos(src, true);
  }
  return ok;
}

const void * ring_buffer_tail_offset(const ring_buffer *buffer, size_t offset) {
  const size_t bytes_used = ring_buffer_used(buffer, true);
  const size_t nbytes = offset * buffer->stride;
  if (nbytes >= bytes_used) {
    return NULL;
  }
  const data_t *tail = buffer->tail;
  const data_t *bufend = ring_buffer_end(buffer);
  size_t nmoved = 0;

  while (nmoved < nbytes) {
    size_t n = imin(bufend - tail, nbytes - nmoved);
    tail += n;
    nmoved += n;
    if (tail == bufend) {
      tail = buffer->data;
    }
  }

  return tail;
}

const void * ring_buffer_head_offset(const ring_buffer *buffer, size_t offset) {
  const size_t bytes_used = ring_buffer_used(buffer, true);
  const size_t nbytes = (offset + 1) * buffer->stride;
  if (nbytes > bytes_used) {
    return NULL;
  }
  const data_t *head = buffer->head;
  const data_t *bufend = ring_buffer_end(buffer);
  size_t nmoved = 0;

  while (nmoved < nbytes) {
    if (head == buffer->data) {
      head = bufend;
    }
    size_t n = imin(head - buffer->data, nbytes - nmoved);
    head -= n;
    nmoved += n;
  }

  return head;
}

void * ring_buffer_head_advance(ring_buffer *buffer) {
  const bool overflow = ring_buffer_handle_overflow(buffer, 1);
  const data_t *bufend = ring_buffer_end(buffer);

  buffer->head += buffer->stride;
  if (buffer->head == bufend) {
    buffer->head = buffer->data;
  }
  if (overflow) {
    buffer->tail = ring_buffer_nextp(buffer, buffer->head);
  }

  return buffer->head;
}

// This one is really just for testing; it's designed to be stupid and
// simple and check that the general search system works, but not to
// be fast.
const void * ring_buffer_search_linear(const ring_buffer *buffer,
                                       ring_predicate *pred, void *data) {
  const size_t n = ring_buffer_used(buffer, false);
  if (n == 0) {
    // Don't do any search here; there is no position such that
    //   buffer[i] < data
    return NULL;
  }
  size_t i = 0;
  const void *xl = ring_buffer_tail_offset(buffer, i), *xr;
  if (!pred(xl, data)) {
    // There will be not a single value here that satisfies the
    // required condition
    return NULL;
  }

  do {
    i++;
    if (i == n) {
      return xl;
    }
    xr = ring_buffer_tail_offset(buffer, i);
    if (!pred(xr, data)) {
      return xl;
    } else {
      xl = xr;
    }
  } while (1);

  return NULL; // # nocov
}

// Do a search.  There a few possibilities of where to start from
// here; we could start with the edges of the array, or we could start
// at one end and grow, or from a position in the array itself.
const void * ring_buffer_search_bisect(const ring_buffer *buffer, size_t i,
                                       ring_predicate *pred, void *data) {
  const size_t n = ring_buffer_used(buffer, false);
  if (n == 0 || i >= n) {
    return NULL;
  }
  int i0 = i, i1 = i;
  const void *x0 = ring_buffer_tail_offset(buffer, i0), *x1;
  int inc = 1;

  // Predicate should return true if we should look further back
  // (increase the tail offset), false otherwise.
  if (pred((void*) x0, data)) { // advance up until we hit the top
    if (i0 >= (int)n - 1) { // guess is already *at* the top.
      return x0;
    }
    i1 = i0 + 1;
    x1 = ring_buffer_tail_offset(buffer, i1);
    while (pred((void*) x1, data)) {
      i0 = i1;
      x0 = x1;
      inc *= 2;
      i1 += inc;
      if (i1 >= (int)n) { // off the end of the buffer
        i1 = n - 1;
        x1 = ring_buffer_tail_offset(buffer, i1);
        if (pred((void*) x1, data)) {
          return x1;
        }
        break;
      }
      x1 = ring_buffer_tail_offset(buffer, i1);
    }
  } else { // advance down
    // who else uses the bisect search?  they'll have the same issue
    // that I see here; odin interpolation.
    if (i0 == 0) { // guess is already at the bottom
      return NULL;
    }
    i1 = i0;
    x1 = x0;
    i0 = i0 - 1;
    x0 = ring_buffer_tail_offset(buffer, i0);
    while (!pred((void*) x0, data)) {
      i1 = i0;
      x1 = x0;
      inc *= 2;
      if (i0 < inc) {
        i0 = 0;
        x0 = ring_buffer_tail_offset(buffer, i0);
        if (!pred((void*) x0, data)) {
          return NULL;
        }
        break;
      }
      i0 -= inc;
      x0 = ring_buffer_tail_offset(buffer, i0);
    }
  }

  // TODO: Here, we'll do a bit of trickery because we'll want to
  // treat the case of the ends being wrapped or not.  This is going
  // to be the case when x0 > x1; in that case we can pop the first
  // point to check at the end of the buffer, compare that and
  // continue.  The actual checks simplify after that because the
  // indices go away and everything is pointer arithmetic, based on
  // the ring buffer stride.  For now, use the bisection search:
  while (i1 - i0 > 1) {
    int i2 = (i1 + i0) / 2;
    const void *x2 = ring_buffer_tail_offset(buffer, i2);
    if (pred((void*) x2, data)) {
      i0 = i2;
      x0 = x2;
    } else {
      i1 = i2;
      x1 = x2;
    }
  }

  return x0;
}

// Internal functions below here...
const data_t * ring_buffer_end(const ring_buffer *buffer) {
  return buffer->data + ring_buffer_bytes_data(buffer);
}

// Given a ring buffer buffer and a pointer to a location within its
// contiguous buffer, return the a pointer to the next logical
// location in the ring buffer.
data_t * ring_buffer_nextp(ring_buffer *buffer, const data_t *p) {
  p += buffer->stride;
  return buffer->data + (p - buffer->data) % ring_buffer_bytes_data(buffer);
}

size_t imin(size_t a, size_t b) {
  return a < b ? a : b;
}

bool ring_buffer_handle_overflow(ring_buffer *buffer, size_t n) {
  bool overflow = ring_buffer_free(buffer, true) < n * buffer->stride;
  if (overflow) {
    switch (buffer->on_overflow) {
    case OVERFLOW_OVERWRITE:
      break; // do nothing
    case OVERFLOW_GROW:
      ring_buffer_grow(buffer, n, false);
      overflow = false;
      break;
#ifdef USING_R
    case OVERFLOW_ERROR:
      Rf_error("Buffer overflow (adding %d elements, but %d available)",
               n, ring_buffer_free(buffer, false));
      break;
#endif
    }
  }
  return overflow;
}
